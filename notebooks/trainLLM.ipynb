{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70cc4204cdad4c209c8906729e99467b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1777b683e9344cb2ad270a58578f4e18",
              "IPY_MODEL_2ee16cf6b9ae4e8a82c88d759a15f015",
              "IPY_MODEL_136c4b9d5dba4f53b00f9ac0a4b00e61"
            ],
            "layout": "IPY_MODEL_3cb01a3366e045e1a1f1608c3e56688e"
          }
        },
        "1777b683e9344cb2ad270a58578f4e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_252abfa1fe3b41fb94e10e30924c34fa",
            "placeholder": "​",
            "style": "IPY_MODEL_3d52ee945dba44cd9e2c0f7cdf1dbb81",
            "value": "Processing Files (2 / 2)      : 100%"
          }
        },
        "2ee16cf6b9ae4e8a82c88d759a15f015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c5b6014b3d495786cfe3aeec321e9c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f56d826eee0422a9c1f1d8025443392",
            "value": 1
          }
        },
        "136c4b9d5dba4f53b00f9ac0a4b00e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44d14039fcb94bb18aa2485cd27922a6",
            "placeholder": "​",
            "style": "IPY_MODEL_e92eb345e1e54978894cc79367564999",
            "value": "  168MB /  168MB, 18.5MB/s  "
          }
        },
        "3cb01a3366e045e1a1f1608c3e56688e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252abfa1fe3b41fb94e10e30924c34fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d52ee945dba44cd9e2c0f7cdf1dbb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67c5b6014b3d495786cfe3aeec321e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3f56d826eee0422a9c1f1d8025443392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44d14039fcb94bb18aa2485cd27922a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92eb345e1e54978894cc79367564999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "061bf6cc6bd946a986861565bf2ebcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c41abffae772456fa1fdb80cf542873a",
              "IPY_MODEL_4f588fadd07747b3a9f365e1e970dee5",
              "IPY_MODEL_27d53f12a7d1415d89bd1f3b104a2ef3"
            ],
            "layout": "IPY_MODEL_8688befecc05457abcff5c66ec84a99a"
          }
        },
        "c41abffae772456fa1fdb80cf542873a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c685c7b5f6d488891f6396b04cdcd6e",
            "placeholder": "​",
            "style": "IPY_MODEL_3c7bde7afa094b04afb49afcf12ab7cf",
            "value": "New Data Upload               : 100%"
          }
        },
        "4f588fadd07747b3a9f365e1e970dee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919588d68ea84235bd9e4c7086856944",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14b0d4fad2db47a5bb5e61cf87c83c4f",
            "value": 1
          }
        },
        "27d53f12a7d1415d89bd1f3b104a2ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5978f8471308459a94e1f8f67e295665",
            "placeholder": "​",
            "style": "IPY_MODEL_f965cf54e57a45279ca5f9507dc33c66",
            "value": "  168MB /  168MB, 18.5MB/s  "
          }
        },
        "8688befecc05457abcff5c66ec84a99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c685c7b5f6d488891f6396b04cdcd6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7bde7afa094b04afb49afcf12ab7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919588d68ea84235bd9e4c7086856944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "14b0d4fad2db47a5bb5e61cf87c83c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5978f8471308459a94e1f8f67e295665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f965cf54e57a45279ca5f9507dc33c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0724fb2bd5c4a79b285e1a9bd6e5cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_264e3577977843afb83fcdf9df069958",
              "IPY_MODEL_6f59a2449da84a10bcab14223777ead4",
              "IPY_MODEL_00f9e56abed94779894ce14a060f84dc"
            ],
            "layout": "IPY_MODEL_e0710cbbecfc42e5be9ab590765076bf"
          }
        },
        "264e3577977843afb83fcdf9df069958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a940cc9ee246f8b505c1e26a1e330f",
            "placeholder": "​",
            "style": "IPY_MODEL_d2be786fb1a3435a9823baf1ca1405f3",
            "value": "  .../adapters/tokenizer.model: 100%"
          }
        },
        "6f59a2449da84a10bcab14223777ead4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c36c6fdbb5441889463865d618b371",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1e2ad7bfb064a6682db162aaeb97c7b",
            "value": 493443
          }
        },
        "00f9e56abed94779894ce14a060f84dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa468ea9df84402ab98998efd3b92445",
            "placeholder": "​",
            "style": "IPY_MODEL_723898a8b93d49ea9d723851eba1d0f4",
            "value": "  493kB /  493kB            "
          }
        },
        "e0710cbbecfc42e5be9ab590765076bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a940cc9ee246f8b505c1e26a1e330f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2be786fb1a3435a9823baf1ca1405f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0c36c6fdbb5441889463865d618b371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e2ad7bfb064a6682db162aaeb97c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa468ea9df84402ab98998efd3b92445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723898a8b93d49ea9d723851eba1d0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee1e30d650f34dd98efff844fcc7be61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7040006621e947d5b082ab1c85e11468",
              "IPY_MODEL_dac777938bad4723a5995dffa8bae74b",
              "IPY_MODEL_6c0eca0cd70447f4ae2bd30793546890"
            ],
            "layout": "IPY_MODEL_4d0fc204ce9d47779972155840d1ad70"
          }
        },
        "7040006621e947d5b082ab1c85e11468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d1e4b8808314cfa8bc8d476f87f33ac",
            "placeholder": "​",
            "style": "IPY_MODEL_56ace8bfec814648a32065f293524840",
            "value": "  ...adapter_model.safetensors: 100%"
          }
        },
        "dac777938bad4723a5995dffa8bae74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f36cb1b6c742209238f17fe0b63afd",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4acb50b31fbb40f4a3fb066e333dc92a",
            "value": 167832240
          }
        },
        "6c0eca0cd70447f4ae2bd30793546890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563583f499a34df99d5e8700b401f61d",
            "placeholder": "​",
            "style": "IPY_MODEL_14403ab2014e4361b973189b16b7536c",
            "value": "  168MB /  168MB            "
          }
        },
        "4d0fc204ce9d47779972155840d1ad70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1e4b8808314cfa8bc8d476f87f33ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ace8bfec814648a32065f293524840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f36cb1b6c742209238f17fe0b63afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4acb50b31fbb40f4a3fb066e333dc92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "563583f499a34df99d5e8700b401f61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14403ab2014e4361b973189b16b7536c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLYYGL9ZrdtR",
        "outputId": "21178cbc-dbf9-44ae-b529-e2bcc6ddfaf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 11 04:19:46 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN_RapA5ryaz",
        "outputId": "eed12779-a340-4d1c-c110-64806ef2afd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the target path\n",
        "target_path = 'your_target_path'\n",
        "\n",
        "# Change the directory\n",
        "os.chdir(target_path)\n",
        "\n",
        "# Verify the change\n",
        "print(f\"Current Working Directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZWtu2aGr-Io",
        "outputId": "d454a723-014b-42bd-b078-18bfcccc74db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/drive/MyDrive/Projects/analytics_copilot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/brej-29/analytics-copilot-text2sql.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aadkNR4tsGis",
        "outputId": "c7d7f27b-4198-470a-abfe-219adc8727f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'analytics-copilot-text2sql' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd analytics-copilot-text2sql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fERZgNXnsU72",
        "outputId": "3646ec7f-3997-4644-87e9-3f3c2347e8e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/analytics_copilot/analytics-copilot-text2sql\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C6GaYnasZuq",
        "outputId": "1cb19d86-a055-4839-efc7-d22dff453e3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.1/381.1 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.1/561.1 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "ibis-framework 9.5.0 requires sqlglot<25.21,>=23.4, but you have sqlglot 28.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate_internal.py --adapter_dir outputs/adapters --device cuda --max_examples 200 --load_in_4bit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRLxbr48sdDq",
        "outputId": "c03d8705-f2ee-425f-e476-85615055f4bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2026-01-11 04:30:22,771] [INFO] __main__ - Loaded 80 validation records from data/processed/val.jsonl (max_examples=200, smoke=False).\n",
            "[2026-01-11 04:30:26,544] [INFO] __main__ - 4-bit loading configuration: load_in_4bit=True, bnb_4bit_quant_type=nf4, bnb_4bit_compute_dtype=bfloat16, bnb_4bit_use_double_quant=True\n",
            "[2026-01-11 04:30:36,298] [INFO] numexpr.utils - NumExpr defaulting to 2 threads.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768105839.654388    3634 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768105839.723092    3634 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768105840.225907    3634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768105840.225950    3634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768105840.225955    3634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768105840.225960    3634 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[2026-01-11 04:30:48,321] [INFO] __main__ - Loading model for inference with base_model=mistralai/Mistral-7B-Instruct-v0.1, adapter_dir=outputs/adapters, device=cuda, load_in_4bit=True, dtype=auto, bnb_4bit_quant_type=nf4, bnb_4bit_compute_dtype=bfloat16, bnb_4bit_use_double_quant=True\n",
            "[2026-01-11 04:30:48,321] [INFO] text2sql.infer - Loading model for inference: base_model=mistralai/Mistral-7B-Instruct-v0.1, adapter_dir=outputs/adapters, device=cuda, load_in_4bit=True, dtype=auto, bnb_compute_dtype=bfloat16, bnb_4bit_quant_type=nf4, bnb_4bit_use_double_quant=True\n",
            "[2026-01-11 04:30:51,164] [INFO] text2sql.infer - Using 4-bit quantization for base model with torch_dtype=torch.float16, compute_dtype=torch.bfloat16, quant_type=nf4, double_quant=True.\n",
            "config.json: 100% 571/571 [00:00<00:00, 4.70MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors.index.json: 25.1kB [00:00, 95.7MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.94G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 537k/4.54G [00:02<5:14:25, 241kB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 14.5M/9.94G [00:03<40:10, 4.12MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 1.72M/4.54G [00:03<2:27:24, 513kB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 47.6M/9.94G [00:03<10:38, 15.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 112M/9.94G [00:06<07:34, 21.6MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 68.8M/4.54G [00:06<05:14, 14.2MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 137M/9.94G [00:07<06:49, 23.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 228M/9.94G [00:07<03:08, 51.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 136M/4.54G [00:07<03:02, 24.2MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 203M/4.54G [00:08<01:54, 37.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 289M/9.94G [00:08<02:59, 53.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 270M/4.54G [00:08<01:17, 55.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 308M/9.94G [00:08<02:56, 54.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 375M/9.94G [00:09<02:16, 70.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 337M/4.54G [00:09<01:03, 65.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 451M/9.94G [00:09<01:51, 85.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 404M/4.54G [00:10<00:55, 74.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 518M/9.94G [00:10<01:30, 105MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 471M/4.54G [00:10<00:44, 90.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 585M/9.94G [00:11<01:43, 90.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 605M/4.54G [00:11<00:36, 108MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 652M/9.94G [00:11<01:42, 90.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 672M/4.54G [00:12<00:38, 100MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 739M/4.54G [00:13<00:42, 89.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 874M/4.54G [00:14<00:35, 102MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 707M/9.94G [00:18<06:15, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 774M/9.94G [00:18<04:26, 34.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 941M/4.54G [00:19<01:29, 40.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 833M/9.94G [00:19<03:36, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 908M/9.94G [00:22<04:33, 33.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 1.01G/4.54G [00:22<01:55, 30.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 949M/9.94G [00:22<03:48, 39.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 1.08G/4.54G [00:23<01:27, 39.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 1.14G/4.54G [00:28<02:18, 24.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 1.28G/4.54G [00:29<01:17, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.35G/4.54G [00:32<01:41, 31.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 1.02G/9.94G [00:32<09:46, 15.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 1.08G/9.94G [00:33<07:12, 20.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.41G/4.54G [00:34<01:28, 35.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.48G/4.54G [00:34<01:05, 46.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.94G [00:34<04:12, 34.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.55G/4.54G [00:34<00:54, 55.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.94G [00:35<03:18, 43.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.61G/4.54G [00:35<00:45, 64.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 1.35G/9.94G [00:35<02:43, 52.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 1.38G/9.94G [00:36<02:50, 50.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.68G/4.54G [00:36<00:42, 67.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.75G/4.54G [00:36<00:34, 79.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.88G/4.54G [00:37<00:20, 130MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 1.40G/9.94G [00:37<03:32, 40.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.95G/4.54G [00:37<00:22, 117MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 2.08G/4.54G [00:38<00:14, 166MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 1.46G/9.94G [00:38<02:51, 49.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 2.15G/4.54G [00:38<00:13, 174MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 2.22G/4.54G [00:38<00:14, 164MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 1.48G/9.94G [00:39<03:43, 37.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 2.28G/4.54G [00:40<00:20, 110MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 2.35G/4.54G [00:43<00:40, 53.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 1.51G/9.94G [00:43<06:38, 21.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 2.42G/4.54G [00:43<00:30, 68.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.94G [00:43<04:02, 34.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 2.48G/4.54G [00:43<00:23, 89.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 2.55G/4.54G [00:47<00:47, 41.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 1.65G/9.94G [00:47<05:36, 24.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.94G [00:48<04:14, 32.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.62G/4.54G [00:48<00:45, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 1.79G/9.94G [00:49<03:08, 43.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 1.88G/9.94G [00:49<01:59, 67.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.69G/4.54G [00:49<00:35, 52.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.75G/4.54G [00:49<00:26, 67.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.94G [00:49<01:49, 73.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.99G/9.94G [00:50<01:36, 82.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.82G/4.54G [00:50<00:24, 71.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 2.03G/9.94G [00:50<01:35, 82.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.89G/4.54G [00:50<00:18, 89.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.95G/4.54G [00:51<00:14, 111MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 3.02G/4.54G [00:52<00:15, 95.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 3.09G/4.54G [00:52<00:12, 113MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 3.16G/4.54G [00:52<00:09, 147MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 2.06G/9.94G [00:52<03:12, 41.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 3.22G/4.54G [00:53<00:11, 117MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 3.29G/4.54G [00:54<00:11, 105MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.94G [00:54<04:18, 30.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 3.36G/4.54G [00:57<00:25, 46.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 3.42G/4.54G [00:57<00:17, 63.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 3.47G/4.54G [00:58<00:15, 67.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 3.54G/4.54G [00:58<00:11, 88.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 3.60G/4.54G [00:58<00:08, 114MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.94G [00:58<09:44, 13.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.94G [00:58<05:04, 25.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 2.22G/9.94G [00:59<03:18, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 2.27G/9.94G [00:59<02:19, 55.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 3.67G/4.54G [01:03<00:25, 34.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.94G [01:04<05:52, 21.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 2.37G/9.94G [01:04<03:46, 33.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 2.44G/9.94G [01:04<02:34, 48.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 3.81G/4.54G [01:05<00:15, 49.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 3.87G/4.54G [01:05<00:11, 60.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.94G/4.54G [01:05<00:07, 76.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 2.50G/9.94G [01:05<02:22, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 2.56G/9.94G [01:06<01:49, 67.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.94G [01:06<01:52, 65.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.94G [01:06<01:25, 85.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 4.01G/4.54G [01:07<00:08, 62.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 4.07G/4.54G [01:07<00:06, 71.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.94G [01:07<02:00, 60.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.94G [01:08<02:15, 53.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.94G [01:09<01:48, 66.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 2.83G/9.94G [01:09<01:26, 82.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.94G [01:10<01:26, 82.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 2.92G/9.94G [01:13<03:31, 33.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.94G [01:14<02:18, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.94G [01:14<02:05, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.94G [01:18<03:32, 32.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 3.22G/9.94G [01:18<01:55, 58.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 4.14G/4.54G [01:18<00:22, 17.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 3.28G/9.94G [01:18<01:39, 67.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 3.35G/9.94G [01:19<01:14, 88.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 3.41G/9.94G [01:19<01:03, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 3.48G/9.94G [01:19<00:48, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 3.53G/9.94G [01:19<00:43, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.94G [01:20<00:43, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 3.64G/9.94G [01:20<00:36, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.94G [01:20<00:35, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.94G [01:20<00:34, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.94G [01:21<00:34, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 3.88G/9.94G [01:22<00:44, 135MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 4.21G/4.54G [01:22<00:18, 17.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 3.95G/9.94G [01:22<00:42, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.94G [01:22<00:45, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 4.03G/9.94G [01:23<00:40, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 4.13G/9.94G [01:23<00:33, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 4.20G/9.94G [01:23<00:29, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 4.27G/9.94G [01:24<00:29, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 4.33G/9.94G [01:24<00:31, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 4.36G/9.94G [01:24<00:30, 185MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 4.27G/4.54G [01:24<00:13, 19.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 4.43G/9.94G [01:25<00:51, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 4.49G/9.94G [01:26<00:44, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 4.52G/9.94G [01:26<00:41, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.94G [01:27<00:53, 100MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 4.34G/4.54G [01:28<00:09, 20.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 4.65G/9.94G [01:28<01:00, 87.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 4.71G/9.94G [01:28<00:46, 111MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.94G [01:28<00:46, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 4.82G/9.94G [01:29<00:36, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.94G [01:32<01:51, 45.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.94G [01:32<01:26, 57.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 5.03G/9.94G [01:33<01:02, 78.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 5.13G/9.94G [01:33<00:45, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.94G [01:33<00:38, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 5.27G/9.94G [01:34<00:35, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 5.30G/9.94G [01:34<00:39, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 5.36G/9.94G [01:35<00:35, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 5.43G/9.94G [01:35<00:28, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 5.50G/9.94G [01:36<00:38, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 5.56G/9.94G [01:38<01:08, 63.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 5.60G/9.94G [01:38<00:55, 77.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 4.41G/4.54G [01:39<00:11, 11.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 5.67G/9.94G [01:39<00:48, 87.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 4.47G/4.54G [01:39<00:04, 16.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 5.72G/9.94G [01:39<00:46, 91.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.94G [01:39<00:31, 129MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.94G [01:40<00:26, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 5.91G/9.94G [01:40<00:24, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.94G [01:42<01:05, 60.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 6.10G/9.94G [01:43<00:37, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.94G [01:43<00:31, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.94G [01:43<00:26, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 6.30G/9.94G [01:46<01:06, 54.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 6.37G/9.94G [01:47<00:49, 71.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 6.43G/9.94G [01:47<00:46, 75.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 6.49G/9.94G [01:47<00:35, 95.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 6.56G/9.94G [01:48<00:29, 116MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 6.64G/9.94G [01:48<00:22, 144MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 6.70G/9.94G [01:48<00:21, 154MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 6.78G/9.94G [01:49<00:20, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 6.84G/9.94G [01:49<00:21, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 6.91G/9.94G [01:52<00:54, 55.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 6.98G/9.94G [01:53<00:40, 73.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.94G [01:53<00:40, 72.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 4.47G/4.54G [01:54<00:04, 16.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 7.02G/9.94G [01:59<02:24, 20.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 4.54G/4.54G [01:59<00:00, 38.1MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 7.05G/9.94G [01:59<02:02, 23.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 7.12G/9.94G [01:59<01:09, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.94G [01:59<00:47, 58.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 7.22G/9.94G [02:00<00:42, 63.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 7.30G/9.94G [02:00<00:29, 90.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 7.37G/9.94G [02:03<00:53, 48.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 7.46G/9.94G [02:03<00:38, 64.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 7.49G/9.94G [02:03<00:33, 73.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 7.56G/9.94G [02:04<00:26, 90.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.94G [02:05<00:39, 59.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.94G [02:06<00:31, 72.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 7.74G/9.94G [02:06<00:23, 94.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 7.78G/9.94G [02:06<00:18, 115MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.94G [02:09<00:37, 55.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 7.92G/9.94G [02:09<00:25, 78.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 7.99G/9.94G [02:09<00:19, 99.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 8.06G/9.94G [02:09<00:14, 128MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 8.11G/9.94G [02:10<00:13, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 8.18G/9.94G [02:10<00:11, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 8.24G/9.94G [02:10<00:09, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 8.31G/9.94G [02:10<00:07, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 8.38G/9.94G [02:11<00:07, 205MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 8.44G/9.94G [02:11<00:07, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 8.51G/9.94G [02:11<00:06, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.94G [02:12<00:05, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.94G [02:12<00:05, 253MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 8.71G/9.94G [02:12<00:04, 269MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 8.78G/9.94G [02:12<00:04, 283MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 8.85G/9.94G [02:12<00:03, 285MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 8.91G/9.94G [02:13<00:03, 294MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 8.98G/9.94G [02:13<00:04, 240MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 9.05G/9.94G [02:13<00:03, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 9.11G/9.94G [02:14<00:02, 280MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 9.18G/9.94G [02:14<00:02, 265MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 9.25G/9.94G [02:14<00:02, 277MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 9.32G/9.94G [02:14<00:02, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.94G [02:15<00:02, 256MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.94G [02:15<00:01, 263MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.94G [02:15<00:02, 216MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.94G [02:17<00:05, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.94G [02:17<00:02, 121MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 9.74G/9.94G [02:18<00:01, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 9.81G/9.94G [02:18<00:00, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 9.88G/9.94G [02:18<00:00, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 9.94G/9.94G [02:18<00:00, 71.6MB/s]\n",
            "Fetching 2 files: 100% 2/2 [02:19<00:00, 69.73s/it] \n",
            "[2026-01-11 04:33:16,161] [INFO] accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [01:05<00:00, 32.72s/it]\n",
            "generation_config.json: 100% 116/116 [00:00<00:00, 1.08MB/s]\n",
            "[2026-01-11 04:34:22,206] [INFO] text2sql.infer - Loading LoRA adapters from outputs/adapters\n",
            "[2026-01-11 04:34:42,761] [INFO] __main__ - Generating prediction for example 1/80\n",
            "The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "[2026-01-11 04:34:51,123] [INFO] __main__ - Generating prediction for example 2/80\n",
            "[2026-01-11 04:34:54,797] [INFO] __main__ - Generating prediction for example 3/80\n",
            "[2026-01-11 04:34:57,421] [INFO] __main__ - Generating prediction for example 4/80\n",
            "[2026-01-11 04:35:04,159] [INFO] __main__ - Generating prediction for example 5/80\n",
            "[2026-01-11 04:35:08,067] [INFO] __main__ - Generating prediction for example 6/80\n",
            "[2026-01-11 04:35:11,311] [INFO] __main__ - Generating prediction for example 7/80\n",
            "[2026-01-11 04:35:14,117] [INFO] __main__ - Generating prediction for example 8/80\n",
            "[2026-01-11 04:35:18,183] [INFO] __main__ - Generating prediction for example 9/80\n",
            "[2026-01-11 04:35:25,208] [INFO] __main__ - Generating prediction for example 10/80\n",
            "[2026-01-11 04:35:29,970] [INFO] __main__ - Generating prediction for example 11/80\n",
            "[2026-01-11 04:35:34,495] [INFO] __main__ - Generating prediction for example 12/80\n",
            "[2026-01-11 04:35:38,413] [INFO] __main__ - Generating prediction for example 13/80\n",
            "[2026-01-11 04:35:43,214] [INFO] __main__ - Generating prediction for example 14/80\n",
            "[2026-01-11 04:35:46,757] [INFO] __main__ - Generating prediction for example 15/80\n",
            "[2026-01-11 04:35:54,208] [INFO] __main__ - Generating prediction for example 16/80\n",
            "[2026-01-11 04:36:00,124] [INFO] __main__ - Generating prediction for example 17/80\n",
            "[2026-01-11 04:36:07,118] [INFO] __main__ - Generating prediction for example 18/80\n",
            "[2026-01-11 04:36:10,111] [INFO] __main__ - Generating prediction for example 19/80\n",
            "[2026-01-11 04:36:18,689] [INFO] __main__ - Generating prediction for example 20/80\n",
            "[2026-01-11 04:36:23,595] [INFO] __main__ - Generating prediction for example 21/80\n",
            "[2026-01-11 04:36:29,223] [INFO] __main__ - Generating prediction for example 22/80\n",
            "[2026-01-11 04:36:34,690] [INFO] __main__ - Generating prediction for example 23/80\n",
            "[2026-01-11 04:36:39,243] [INFO] __main__ - Generating prediction for example 24/80\n",
            "[2026-01-11 04:36:42,009] [INFO] __main__ - Generating prediction for example 25/80\n",
            "[2026-01-11 04:36:45,857] [INFO] __main__ - Generating prediction for example 26/80\n",
            "[2026-01-11 04:36:48,888] [INFO] __main__ - Generating prediction for example 27/80\n",
            "[2026-01-11 04:36:51,484] [INFO] __main__ - Generating prediction for example 28/80\n",
            "[2026-01-11 04:36:56,664] [INFO] __main__ - Generating prediction for example 29/80\n",
            "[2026-01-11 04:37:06,226] [INFO] __main__ - Generating prediction for example 30/80\n",
            "[2026-01-11 04:37:12,131] [INFO] __main__ - Generating prediction for example 31/80\n",
            "[2026-01-11 04:37:23,515] [INFO] __main__ - Generating prediction for example 32/80\n",
            "[2026-01-11 04:37:25,703] [INFO] __main__ - Generating prediction for example 33/80\n",
            "[2026-01-11 04:37:33,169] [INFO] __main__ - Generating prediction for example 34/80\n",
            "[2026-01-11 04:37:36,571] [INFO] __main__ - Generating prediction for example 35/80\n",
            "[2026-01-11 04:37:42,958] [INFO] __main__ - Generating prediction for example 36/80\n",
            "[2026-01-11 04:37:47,829] [INFO] __main__ - Generating prediction for example 37/80\n",
            "[2026-01-11 04:37:52,093] [INFO] __main__ - Generating prediction for example 38/80\n",
            "[2026-01-11 04:37:57,827] [INFO] __main__ - Generating prediction for example 39/80\n",
            "[2026-01-11 04:38:00,675] [INFO] __main__ - Generating prediction for example 40/80\n",
            "[2026-01-11 04:38:04,197] [INFO] __main__ - Generating prediction for example 41/80\n",
            "[2026-01-11 04:38:07,975] [INFO] __main__ - Generating prediction for example 42/80\n",
            "[2026-01-11 04:38:10,183] [INFO] __main__ - Generating prediction for example 43/80\n",
            "[2026-01-11 04:38:13,735] [INFO] __main__ - Generating prediction for example 44/80\n",
            "[2026-01-11 04:38:17,023] [INFO] __main__ - Generating prediction for example 45/80\n",
            "[2026-01-11 04:38:23,313] [INFO] __main__ - Generating prediction for example 46/80\n",
            "[2026-01-11 04:38:30,974] [INFO] __main__ - Generating prediction for example 47/80\n",
            "[2026-01-11 04:38:34,595] [INFO] __main__ - Generating prediction for example 48/80\n",
            "[2026-01-11 04:38:36,910] [INFO] __main__ - Generating prediction for example 49/80\n",
            "[2026-01-11 04:38:44,654] [INFO] __main__ - Generating prediction for example 50/80\n",
            "[2026-01-11 04:38:50,118] [INFO] __main__ - Generating prediction for example 51/80\n",
            "[2026-01-11 04:38:57,337] [INFO] __main__ - Generating prediction for example 52/80\n",
            "[2026-01-11 04:39:03,621] [INFO] __main__ - Generating prediction for example 53/80\n",
            "[2026-01-11 04:39:11,153] [INFO] __main__ - Generating prediction for example 54/80\n",
            "[2026-01-11 04:39:14,173] [INFO] __main__ - Generating prediction for example 55/80\n",
            "[2026-01-11 04:39:17,752] [INFO] __main__ - Generating prediction for example 56/80\n",
            "[2026-01-11 04:39:20,502] [INFO] __main__ - Generating prediction for example 57/80\n",
            "[2026-01-11 04:39:23,826] [INFO] __main__ - Generating prediction for example 58/80\n",
            "[2026-01-11 04:39:29,515] [INFO] __main__ - Generating prediction for example 59/80\n",
            "[2026-01-11 04:39:32,059] [INFO] __main__ - Generating prediction for example 60/80\n",
            "[2026-01-11 04:39:36,885] [INFO] __main__ - Generating prediction for example 61/80\n",
            "[2026-01-11 04:39:48,183] [INFO] __main__ - Generating prediction for example 62/80\n",
            "[2026-01-11 04:39:51,804] [INFO] __main__ - Generating prediction for example 63/80\n",
            "[2026-01-11 04:39:54,862] [INFO] __main__ - Generating prediction for example 64/80\n",
            "[2026-01-11 04:39:57,882] [INFO] __main__ - Generating prediction for example 65/80\n",
            "[2026-01-11 04:40:02,669] [INFO] __main__ - Generating prediction for example 66/80\n",
            "[2026-01-11 04:40:05,029] [INFO] __main__ - Generating prediction for example 67/80\n",
            "[2026-01-11 04:40:16,955] [INFO] __main__ - Generating prediction for example 68/80\n",
            "[2026-01-11 04:40:21,980] [INFO] __main__ - Generating prediction for example 69/80\n",
            "[2026-01-11 04:40:26,386] [INFO] __main__ - Generating prediction for example 70/80\n",
            "[2026-01-11 04:40:33,068] [INFO] __main__ - Generating prediction for example 71/80\n",
            "[2026-01-11 04:40:37,880] [INFO] __main__ - Generating prediction for example 72/80\n",
            "[2026-01-11 04:40:44,632] [INFO] __main__ - Generating prediction for example 73/80\n",
            "[2026-01-11 04:40:49,896] [INFO] __main__ - Generating prediction for example 74/80\n",
            "[2026-01-11 04:40:58,751] [INFO] __main__ - Generating prediction for example 75/80\n",
            "[2026-01-11 04:41:03,532] [INFO] __main__ - Generating prediction for example 76/80\n",
            "[2026-01-11 04:41:08,939] [INFO] __main__ - Generating prediction for example 77/80\n",
            "[2026-01-11 04:41:13,441] [INFO] __main__ - Generating prediction for example 78/80\n",
            "[2026-01-11 04:41:15,379] [INFO] __main__ - Generating prediction for example 79/80\n",
            "[2026-01-11 04:41:22,745] [INFO] __main__ - Generating prediction for example 80/80\n",
            "[2026-01-11 04:41:25,908] [INFO] __main__ - Evaluation metrics: {'n_examples': 80, 'exact_match': {'count': 28, 'rate': 0.35}, 'no_values_em': {'count': 28, 'rate': 0.35}, 'parse_success': {'count': 80, 'rate': 1.0}, 'schema_adherence': {'count': 78, 'rate': 0.975}}\n",
            "[2026-01-11 04:41:25,920] [INFO] __main__ - Internal evaluation reports written to reports/eval_internal.json and reports/eval_internal.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate_spider_external.py --adapter_dir outputs/adapters --device cuda --max_examples 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0CmzegjtTRu",
        "outputId": "7a8c86a1-90b4-42e5-98ff-c3ab59ddb292"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2026-01-11 04:43:13,073] [INFO] __main__ - Running Spider evaluation with spider_source=xlangai/spider, schema_source=richardr1126/spider-schema, split=validation\n",
            "[2026-01-11 04:43:13,741] [INFO] numexpr.utils - NumExpr defaulting to 2 threads.\n",
            "[2026-01-11 04:43:14,255] [INFO] datasets - TensorFlow version 2.19.0 available.\n",
            "[2026-01-11 04:43:14,257] [INFO] datasets - JAX version 0.7.2 available.\n",
            "[2026-01-11 04:43:17,492] [INFO] __main__ - Loading Spider dataset 'xlangai/spider' (split=validation) and schema 'richardr1126/spider-schema' from Hugging Face.\n",
            "README.md: 5.51kB [00:00, 19.2MB/s]\n",
            "spider/train-00000-of-00001.parquet: 100% 831k/831k [00:01<00:00, 653kB/s]\n",
            "spider/validation-00000-of-00001.parquet: 100% 126k/126k [00:00<00:00, 256kB/s]\n",
            "Generating train split: 100% 7000/7000 [00:00<00:00, 97985.33 examples/s]\n",
            "Generating validation split: 100% 1034/1034 [00:00<00:00, 168909.11 examples/s]\n",
            "README.md: 1.36kB [00:00, 777kB/s]\n",
            "spider_schema_rows_v2.json: 192kB [00:00, 159MB/s]\n",
            "Generating train split: 166 examples [00:00, 5203.11 examples/s]\n",
            "[2026-01-11 04:43:26,234] [INFO] text2sql.eval.spider - Spider schema dataset columns: ['db_id', 'Schema (values (type))', 'Primary Keys', 'Foreign Keys']\n",
            "[2026-01-11 04:43:26,240] [INFO] text2sql.eval.spider - Loaded 166 Spider schema entries using field 'Schema (values (type))'. Sample db_ids: ['academic', 'activity_1', 'aircraft', 'allergy_1', 'apartment_rentals']\n",
            "[2026-01-11 04:43:26,330] [INFO] __main__ - Total Spider examples: 1034\n",
            "[2026-01-11 04:43:26,330] [INFO] __main__ - Unique Spider db_ids: 20\n",
            "[2026-01-11 04:43:26,330] [INFO] __main__ - Total schema db_ids: 166\n",
            "[2026-01-11 04:43:26,331] [INFO] __main__ - Intersection size (db_ids in both): 20\n",
            "[2026-01-11 04:43:26,331] [INFO] __main__ - After joining with schema: evaluated_count=1034, skipped_due_to_missing_schema=0\n",
            "[2026-01-11 04:43:26,331] [INFO] __main__ - Loaded 50 Spider examples with matching schema entries.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768106611.265813    7014 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768106611.278723    7014 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768106611.327969    7014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768106611.328006    7014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768106611.328014    7014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768106611.328020    7014 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[2026-01-11 04:43:38,777] [INFO] __main__ - Loading model for inference with base_model=mistralai/Mistral-7B-Instruct-v0.1, adapter_dir=outputs/adapters, device=cuda, load_in_4bit=None, dtype=auto\n",
            "[2026-01-11 04:43:38,777] [INFO] text2sql.infer - Loading model for inference: base_model=mistralai/Mistral-7B-Instruct-v0.1, adapter_dir=outputs/adapters, device=cuda, load_in_4bit=True, dtype=auto, bnb_compute_dtype=float16, bnb_4bit_quant_type=nf4, bnb_4bit_use_double_quant=True\n",
            "[2026-01-11 04:43:38,958] [INFO] text2sql.infer - Using 4-bit quantization for base model with torch_dtype=torch.float16, compute_dtype=torch.float16, quant_type=nf4, double_quant=True.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "[2026-01-11 04:43:42,649] [INFO] accelerate.utils.modeling - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [01:06<00:00, 33.26s/it]\n",
            "[2026-01-11 04:44:49,806] [INFO] text2sql.infer - Loading LoRA adapters from outputs/adapters\n",
            "[2026-01-11 04:44:51,749] [INFO] __main__ - Generating prediction for Spider example 1/50 (db_id=concert_singer)\n",
            "The following generation flags are not valid and may be ignored: ['top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "[2026-01-11 04:44:57,757] [INFO] __main__ - Generating prediction for Spider example 2/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:44:59,976] [INFO] __main__ - Generating prediction for Spider example 3/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:45:22,595] [INFO] __main__ - Generating prediction for Spider example 4/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:45:27,789] [INFO] __main__ - Generating prediction for Spider example 5/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:45:36,656] [INFO] __main__ - Generating prediction for Spider example 6/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:45:46,661] [INFO] __main__ - Generating prediction for Spider example 7/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:45:58,414] [INFO] __main__ - Generating prediction for Spider example 8/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:08,309] [INFO] __main__ - Generating prediction for Spider example 9/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:17,839] [INFO] __main__ - Generating prediction for Spider example 10/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:20,561] [INFO] __main__ - Generating prediction for Spider example 11/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:22,929] [INFO] __main__ - Generating prediction for Spider example 12/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:25,840] [INFO] __main__ - Generating prediction for Spider example 13/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:29,192] [INFO] __main__ - Generating prediction for Spider example 14/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:32,240] [INFO] __main__ - Generating prediction for Spider example 15/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:36,210] [INFO] __main__ - Generating prediction for Spider example 16/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:41,262] [INFO] __main__ - Generating prediction for Spider example 17/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:43,415] [INFO] __main__ - Generating prediction for Spider example 18/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:46,807] [INFO] __main__ - Generating prediction for Spider example 19/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:49,845] [INFO] __main__ - Generating prediction for Spider example 20/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:53,754] [INFO] __main__ - Generating prediction for Spider example 21/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:46:57,171] [INFO] __main__ - Generating prediction for Spider example 22/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:00,479] [INFO] __main__ - Generating prediction for Spider example 23/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:03,211] [INFO] __main__ - Generating prediction for Spider example 24/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:10,787] [INFO] __main__ - Generating prediction for Spider example 25/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:20,279] [INFO] __main__ - Generating prediction for Spider example 26/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:27,177] [INFO] __main__ - Generating prediction for Spider example 27/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:35,668] [INFO] __main__ - Generating prediction for Spider example 28/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:41,096] [INFO] __main__ - Generating prediction for Spider example 29/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:44,867] [INFO] __main__ - Generating prediction for Spider example 30/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:48,413] [INFO] __main__ - Generating prediction for Spider example 31/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:54,417] [INFO] __main__ - Generating prediction for Spider example 32/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:47:58,982] [INFO] __main__ - Generating prediction for Spider example 33/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:03,400] [INFO] __main__ - Generating prediction for Spider example 34/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:08,023] [INFO] __main__ - Generating prediction for Spider example 35/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:10,786] [INFO] __main__ - Generating prediction for Spider example 36/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:14,733] [INFO] __main__ - Generating prediction for Spider example 37/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:17,835] [INFO] __main__ - Generating prediction for Spider example 38/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:20,366] [INFO] __main__ - Generating prediction for Spider example 39/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:23,978] [INFO] __main__ - Generating prediction for Spider example 40/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:28,835] [INFO] __main__ - Generating prediction for Spider example 41/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:32,740] [INFO] __main__ - Generating prediction for Spider example 42/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:37,853] [INFO] __main__ - Generating prediction for Spider example 43/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:42,456] [INFO] __main__ - Generating prediction for Spider example 44/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:47,282] [INFO] __main__ - Generating prediction for Spider example 45/50 (db_id=concert_singer)\n",
            "[2026-01-11 04:48:50,344] [INFO] __main__ - Generating prediction for Spider example 46/50 (db_id=pets_1)\n",
            "[2026-01-11 04:48:57,753] [INFO] __main__ - Generating prediction for Spider example 47/50 (db_id=pets_1)\n",
            "[2026-01-11 04:49:01,978] [INFO] __main__ - Generating prediction for Spider example 48/50 (db_id=pets_1)\n",
            "[2026-01-11 04:49:07,180] [INFO] __main__ - Generating prediction for Spider example 49/50 (db_id=pets_1)\n",
            "[2026-01-11 04:49:11,009] [INFO] __main__ - Generating prediction for Spider example 50/50 (db_id=pets_1)\n",
            "[2026-01-11 04:49:13,739] [INFO] __main__ - Spider evaluation metrics: {'n_examples': 50, 'exact_match': {'count': 0, 'rate': 0.0}, 'no_values_em': {'count': 0, 'rate': 0.0}, 'parse_success': {'count': 50, 'rate': 1.0}, 'schema_adherence': {'count': 38, 'rate': 0.76}}\n",
            "[2026-01-11 04:49:15,290] [INFO] __main__ - Spider external evaluation reports written to reports/eval_spider.json and reports/eval_spider.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers accelerate peft safetensors huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_qEvrxhvvcE",
        "outputId": "5d7f5a5c-2410-4334-fac2-f1563b5722ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/557.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"your_token_here\")"
      ],
      "metadata": {
        "id": "MBQ5RLnPwWSi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vR6hz3BX-yR",
        "outputId": "bef63977-ad07-4d70-a361-f6001ff11cb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/analytics_copilot/analytics-copilot-text2sql\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import upload_folder\n",
        "import os\n",
        "\n",
        "# 2) upload your adapter folder to the model repo\n",
        "REPO_ID = \"BrejBala/analytics-copilot-mistral7b-text2sql-adapter\"\n",
        "ADAPTER_DIR = \"outputs/adapters\"  # adjust if needed\n",
        "\n",
        "upload_folder(\n",
        "    folder_path=ADAPTER_DIR,\n",
        "    repo_id=REPO_ID,\n",
        "    repo_type=\"model\",     # important: it's a model repo\n",
        "    commit_message=\"Upload LoRA adapter for Text-to-SQL\",\n",
        ")\n",
        "print(\"Uploaded adapter folder to:\", REPO_ID)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "70cc4204cdad4c209c8906729e99467b",
            "1777b683e9344cb2ad270a58578f4e18",
            "2ee16cf6b9ae4e8a82c88d759a15f015",
            "136c4b9d5dba4f53b00f9ac0a4b00e61",
            "3cb01a3366e045e1a1f1608c3e56688e",
            "252abfa1fe3b41fb94e10e30924c34fa",
            "3d52ee945dba44cd9e2c0f7cdf1dbb81",
            "67c5b6014b3d495786cfe3aeec321e9c",
            "3f56d826eee0422a9c1f1d8025443392",
            "44d14039fcb94bb18aa2485cd27922a6",
            "e92eb345e1e54978894cc79367564999",
            "061bf6cc6bd946a986861565bf2ebcd9",
            "c41abffae772456fa1fdb80cf542873a",
            "4f588fadd07747b3a9f365e1e970dee5",
            "27d53f12a7d1415d89bd1f3b104a2ef3",
            "8688befecc05457abcff5c66ec84a99a",
            "4c685c7b5f6d488891f6396b04cdcd6e",
            "3c7bde7afa094b04afb49afcf12ab7cf",
            "919588d68ea84235bd9e4c7086856944",
            "14b0d4fad2db47a5bb5e61cf87c83c4f",
            "5978f8471308459a94e1f8f67e295665",
            "f965cf54e57a45279ca5f9507dc33c66",
            "d0724fb2bd5c4a79b285e1a9bd6e5cb3",
            "264e3577977843afb83fcdf9df069958",
            "6f59a2449da84a10bcab14223777ead4",
            "00f9e56abed94779894ce14a060f84dc",
            "e0710cbbecfc42e5be9ab590765076bf",
            "11a940cc9ee246f8b505c1e26a1e330f",
            "d2be786fb1a3435a9823baf1ca1405f3",
            "b0c36c6fdbb5441889463865d618b371",
            "c1e2ad7bfb064a6682db162aaeb97c7b",
            "aa468ea9df84402ab98998efd3b92445",
            "723898a8b93d49ea9d723851eba1d0f4",
            "ee1e30d650f34dd98efff844fcc7be61",
            "7040006621e947d5b082ab1c85e11468",
            "dac777938bad4723a5995dffa8bae74b",
            "6c0eca0cd70447f4ae2bd30793546890",
            "4d0fc204ce9d47779972155840d1ad70",
            "9d1e4b8808314cfa8bc8d476f87f33ac",
            "56ace8bfec814648a32065f293524840",
            "69f36cb1b6c742209238f17fe0b63afd",
            "4acb50b31fbb40f4a3fb066e333dc92a",
            "563583f499a34df99d5e8700b401f61d",
            "14403ab2014e4361b973189b16b7536c"
          ]
        },
        "id": "-cdSPzfQaJRY",
        "outputId": "509ef325-6393-4025-ff48-dc506c710e6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cc4204cdad4c209c8906729e99467b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "061bf6cc6bd946a986861565bf2ebcd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  .../adapters/tokenizer.model: 100%|##########|  493kB /  493kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0724fb2bd5c4a79b285e1a9bd6e5cb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...adapter_model.safetensors:   0%|          |  560kB /  168MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee1e30d650f34dd98efff844fcc7be61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded adapter folder to: BrejBala/analytics-copilot-mistral7b-text2sql-adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, os, json\n",
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "ENDPOINT_URL = \"https://o0mmkmv1itfrikie.us-east4.gcp.endpoints.huggingface.cloud\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "prompt = \"\"\"### Instruction:\n",
        "Write a SQL query that answers the user's question using ONLY the tables and columns provided in the schema.\n",
        "\n",
        "### Input:\n",
        "### Schema:\n",
        "CREATE TABLE Customers (customer_id VARCHAR); CREATE TABLE Accounts (customer_id VARCHAR)\n",
        "\n",
        "### Question:\n",
        "Show the number of all customers without an account.\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "payload = {\n",
        "    \"inputs\": prompt,\n",
        "    \"parameters\": {\n",
        "        \"max_new_tokens\": 128,\n",
        "        \"temperature\": 0.1,\n",
        "        \"adapter_id\": \"BrejBala/analytics-copilot-mistral7b-text2sql-adapter\"\n",
        "    }\n",
        "}\n",
        "\n",
        "r = requests.post(ENDPOINT_URL, headers=headers, data=json.dumps(payload), timeout=120)\n",
        "print(r.status_code)\n",
        "print(r.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtYkWsnMz4EV",
        "outputId": "53418830-6e36-4ba2-e3d9-db3eb6ca3e21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "[{\"generated_text\":\"### Instruction:\\nWrite a SQL query that answers the user's question using ONLY the tables and columns provided in the schema.\\n\\n### Input:\\n### Schema:\\nCREATE TABLE Customers (customer_id VARCHAR); CREATE TABLE Accounts (customer_id VARCHAR)\\n\\n### Question:\\nShow the number of all customers without an account.\\n\\n### Response:\\nSELECT COUNT(*) AS \\\"Number of Customers without an Account\\\" FROM Customers WHERE customer_id NOT IN (SELECT customer_id FROM Accounts);\\n\\n### Explanation:\\n\\n### Complexity:\\n\\n### Tags:\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "data = json.loads(r.text)\n",
        "generated_text = data[0]['generated_text']\n",
        "try:\n",
        "    parts = re.split(r'### Response:\\s*|### Explanation:', generated_text, flags=re.IGNORECASE)\n",
        "\n",
        "    # The content we want is the second element (index 1) in the split list\n",
        "    if len(parts) > 2:\n",
        "        response_sql = parts[1].strip()\n",
        "        # Clean up the escaped quotes just in case the model used them (e.g., \\\\\")\n",
        "        response_sql = response_sql.replace('\\\\\"', '\"')\n",
        "    else:\n",
        "        response_sql = \"Could not parse response section using regex.\"\n",
        "\n",
        "except Exception as e:\n",
        "    response_sql = f\"An error occurred: {e}\"\n",
        "print(\"--- Analytics Copilot Output ---\")\n",
        "\n",
        "# Present the full text in a readable form\n",
        "print(\"\\n### Full Parsed Text:\")\n",
        "print(generated_text.replace('\\\\n', '\\n'))\n",
        "\n",
        "# Present ONLY the response\n",
        "print(\"\\n### Extracted SQL Response:\")\n",
        "print(response_sql.replace('\\\\\"', '\"'))\n",
        "\n",
        "print(\"--------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4iKK7cL3nhG",
        "outputId": "fe1eb8f9-a0e1-42e0-9cd7-995f4e60491f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Analytics Copilot Output ---\n",
            "\n",
            "### Full Parsed Text:\n",
            "### Instruction:\n",
            "Write a SQL query that answers the user's question using ONLY the tables and columns provided in the schema.\n",
            "\n",
            "### Input:\n",
            "### Schema:\n",
            "CREATE TABLE Customers (customer_id VARCHAR); CREATE TABLE Accounts (customer_id VARCHAR)\n",
            "\n",
            "### Question:\n",
            "Show the number of all customers without an account.\n",
            "\n",
            "### Response:\n",
            "SELECT COUNT(*) AS \"Number of Customers without an Account\" FROM Customers WHERE customer_id NOT IN (SELECT customer_id FROM Accounts);\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "### Complexity:\n",
            "\n",
            "### Tags:\n",
            "\n",
            "### Extracted SQL Response:\n",
            "SELECT COUNT(*) AS \"Number of Customers without an Account\" FROM Customers WHERE customer_id NOT IN (SELECT customer_id FROM Accounts);\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQeXEn9Sldll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}